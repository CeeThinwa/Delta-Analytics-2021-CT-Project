{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "isolated-provision",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for the Delta Analytics Teaching Fellowship\n",
    "\n",
    "**Author:** *Cynthia Thinwa*\n",
    "\n",
    "## INTRODUCTION\n",
    "\n",
    "### DATA HANDLING PRACTICES:\n",
    "\n",
    "* Based on Twitter API best practice, the actual data will not be shared, only Twitter's tweet IDs for future reference\n",
    "* The data will be cleaned to remove personally identifiable information like emails and phone numbers\n",
    "* Exploratory Data Analysis will be described here purely for the basis of describing how the dataset was aggregated in order to be fed into the ML model\n",
    "\n",
    "$$~~$$\n",
    "\n",
    "## EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The raw data was loaded as follows, with the following characteristics:\n",
    "\n",
    "1. The number of tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "commercial-metabolism",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ct\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "residential-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(dplyr)\n",
    "library(wordcloud)\n",
    "library(RColorBrewer)\n",
    "library(rtweet)\n",
    "library(tidytext)\n",
    "library(ggplot2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atomic-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 36305\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "url <- \"C:/storage/Personal drive backup/Career/Post-Masters/Delta Analytics Teaching Fellowship/EDA/2.kotdata.csv\"\n",
    "DATFdata <- read.delim(url)\n",
    "dim(DATFdata)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-difference",
   "metadata": {},
   "source": [
    "\n",
    "2. The number of unique conversations had:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "french-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 35388\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "DATFdata$conversation_id <- factor(DATFdata$conversation_id)\n",
    "DATFdata$id <- factor(DATFdata$id)\n",
    "\n",
    "dim(as.data.frame(table(DATFdata$conversation_id)))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-indianapolis",
   "metadata": {},
   "source": [
    "\n",
    "3. The number of unique users speaking:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nuclear-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 11049\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "DATFdata$user_id <- factor(DATFdata$user_id)\n",
    "\n",
    "dim(as.data.frame(table(DATFdata$user_id)))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-fifth",
   "metadata": {},
   "source": [
    "\n",
    "4. The most frequent language of posting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "banned-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language Frequency\n",
      "8       en     27504\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "lang <- as.data.frame(table(DATFdata$language))\n",
    "colnames(lang) <- c('Language','Frequency')\n",
    "head(lang[order(lang$Freq, decreasing = TRUE),],n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-toyota",
   "metadata": {},
   "source": [
    "\n",
    "5. The date on which most tweets were posted (tweets were from 1st June 2020 UTC+3 upto 1st June 2021 UTC+3): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "buried-banner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date Frequency\n",
      "262 2021-02-17       406\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "dates <- as.data.frame(table(DATFdata$date))\n",
    "colnames(dates) <- c('Date','Frequency')\n",
    "head(dates[order(dates$Freq, decreasing = TRUE),],n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-egyptian",
   "metadata": {},
   "source": [
    "\n",
    "### Text transformation\n",
    "\n",
    "Text cleaning was as follows, using `eng_tweets$tweet[4]` as an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sapphire-parker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%R is a cell magic, but the cell body is empty. Did you mean the line magic %R (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# Get organic tweets first; found that all tweets were organic!\n",
    "\n",
    "# get only English ones:\n",
    "eng_tweets <- DATFdata[DATFdata$language=='en',]; eng_tweets$tweet[4]\n",
    "\n",
    "# Remove funny symbols\n",
    "eng_tweets$tweet <- iconv(eng_tweets$tweet, from = 'UTF-8', to = 'ISO-8859-1', sub = ''); eng_tweets$tweet[4]\n",
    "\n",
    "eng_tweets$tweet <- iconv(eng_tweets$tweet, from = 'ISO-8859-1', to = 'UTF-8', sub = ''); eng_tweets$tweet[4]\n",
    "\n",
    "eng_tweets$tweet <- gsub(\"https\\\\S*\", \"\", eng_tweets$tweet); eng_tweets$tweet[4] #remove urls\n",
    "\n",
    "eng_tweets$tweet <- gsub(\"@\\\\S*\", \"\", eng_tweets$tweet); eng_tweets$tweet[4] #remove mentions\n",
    "\n",
    "eng_tweets$tweet <- gsub(\"#\\\\S*\", \"\", eng_tweets$tweet); eng_tweets$tweet[4] #remove hashtags\n",
    "\n",
    "eng_tweets$tweet <- gsub(\"[\\r\\n]\", \" \", eng_tweets$tweet); eng_tweets$tweet[4] #remove newline characters\n",
    "\n",
    "#(we have separate columns with the details)\n",
    "# Punctuation was managed as follows:\n",
    "eng_tweets$tweet <- gsub(\"'\", \"\", eng_tweets$tweet); eng_tweets$tweet[4]\n",
    "\n",
    "eng_tweets$tweet <- gsub(\"[[:punct:]]\", \" \", eng_tweets$tweet); eng_tweets$tweet[4]\n",
    "\n",
    "eng_tweets$tweet <- gsub(\"amp\", \"\", eng_tweets$tweet); eng_tweets$tweet[4] # remove ampersands\n",
    "\n",
    "# Finally, everything was made lowercase\n",
    "eng_tweets$tweet <- tolower(eng_tweets$tweet); eng_tweets$tweet[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Tokenize words\n",
    "Words <- eng_tweets %>%\n",
    "  select(tweet) %>%\n",
    "  unnest_tokens(word, tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-hawaiian",
   "metadata": {},
   "source": [
    "\n",
    "### Word Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "Words %>% # gives you a bar chart of the most frequent words found in the tweets\n",
    "  count(word, sort = TRUE) %>%\n",
    "  top_n(15) %>%\n",
    "  mutate(word = reorder(word, n)) %>%\n",
    "  ggplot(aes(x = word, y = n)) +\n",
    "  geom_col() +\n",
    "  xlab(NULL) +\n",
    "  coord_flip() +\n",
    "  labs(y = \"Count\",\n",
    "       x = \"Unique words\",\n",
    "       title = \"Most frequent words found in the #KOT tweets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
